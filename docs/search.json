[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Minicurso de Estatística Espacial",
    "section": "",
    "text": "0.0.1 Instalação e execução\nIntrodução\nEste minicurso apresenta métodos para análises espacial em três contextos: dados agregados por áreas, processos pontuais e geoestatística. O público-alvo são todos com conhecimentos básicos em regressão e estatística espacial.\nInstale os pacotes necessários em uma sessão R (ajuste conforme sua versão):\nCom quarto instalado, renderize o livro (após todas as alterações):",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao Minicurso de Estatística Espacial</span>"
    ]
  },
  {
    "objectID": "index.html#estrutura-do-minicurso-seções",
    "href": "index.html#estrutura-do-minicurso-seções",
    "title": "Minicurso de Estatística Espacial",
    "section": "0.1 Estrutura do Minicurso (Seções)",
    "text": "0.1 Estrutura do Minicurso (Seções)\n\nSeção A — Instalação e Introdução: pacotes, estrutura de arquivos, como renderizar.\nSeção B — Dados de Áreas: teoria, matrizes de pesos, Moran’s I, SAR/SEM, exemplos em R, exercícios.\nSeção C — Processos Pontuais: Poisson inhomogêneo, LGCP, ajuste com spatstat, exercícios.\nSeção D — Geoestatística: variogramas, ajuste, krigagem universal, predição, exercícios.\nSeção E — Espaço-Temporal (opcional): esboço de modelagem espaço-temporal e referências.\nApêndices: soluções dos exercícios, scripts auxiliares e referência única ao livro.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao Minicurso de Estatística Espacial</span>"
    ]
  },
  {
    "objectID": "index.html#exercícios",
    "href": "index.html#exercícios",
    "title": "Minicurso de Estatística Espacial",
    "section": "0.2 Exercícios",
    "text": "0.2 Exercícios\nSeção B — Dados de Áreas\n\nAjuste um modelo OLS CRIME ~ INC + HOVAL com columbus. Calcule Moran’s I nos resíduos e interprete. (Dica: lm.morantest())\nAjuste um SAR e um SEM para os mesmos dados. Compare os valores de AIC e interprete rho e lambda.\n\nSeção C — Processos Pontuais\n\nUsando bei, ajuste ppm(bei ~ elev + grad, data = bei.extra). Quais covariáveis são significativas? Faça um P-P plot para avaliar ajuste.\nAjuste um kppm(..., clusters = \"LGCP\") e compare os parâmetros do campo aleatório (sigma2 e escala) com o modelo Poisson.\n\nSeção D — Geoestatística\n\nEm meuse, ajuste uma tendência de log(zinc) ~ sqrt(dist) e calcule o variograma dos resíduos. Ajuste um modelo exponencial e reporte nugget, sill e range.\nRealize krigagem universal para predizer log(zinc) em uma grade e produza um mapa de predição e outro de erro padrão.\n\nSeção E — Espaço-Temporal (exercício conceitual)\n\nEscreva um esboço de como separaria o variograma espaço-temporal em componentes espaço, tempo e interação para um conjunto de séries de temperatura.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao Minicurso de Estatística Espacial</span>"
    ]
  },
  {
    "objectID": "index.html#apêndice-a-soluções-respostas-rápidas",
    "href": "index.html#apêndice-a-soluções-respostas-rápidas",
    "title": "Minicurso de Estatística Espacial",
    "section": "0.3 Apêndice A — Soluções (respostas rápidas)",
    "text": "0.3 Apêndice A — Soluções (respostas rápidas)\nSeção B — Dados de Áreas (exemplo de solução)\n# OLS e Moran\ndata(columbus)\nb &lt;- poly2nb(columbus)\nlistw &lt;- nb2listw(nb, style = \"W\")\nmodelo_ols &lt;- lm(CRIME ~ INC + HOVAL, data = columbus)\nlm.morantest(modelo_ols, listw)\n\n# SAR e SEM\nmodelo_sar &lt;- lagsarlm(CRIME ~ INC + HOVAL, data = columbus, listw = listw)\nmodelo_sem &lt;- errorsarlm(CRIME ~ INC + HOVAL, data = columbus, listw = listw)\nAIC(modelo_ols, modelo_sar, modelo_sem)\nSeção C — Processos Pontuais (exemplo de solução)\nlibrary(spatstat)\ndata(bei); data(bei.extra)\nmodelo_ppm &lt;- ppm(bei ~ elev + grad, data = bei.extra)\nsummary(modelo_ppm)\n\nmodelo_lgcp &lt;- kppm(bei ~ elev + grad, data = bei.extra, clusters = \"LGCP\")\nsummary(modelo_lgcp)\nSeção D — Geoestatística (exemplo de solução)\nlibrary(gstat); library(sp)\ndata(meuse); coordinates(meuse)=~x+y\nv &lt;- variogram(log(zinc) ~ sqrt(dist), meuse)\nvm &lt;- fit.variogram(v, vgm(psill=1, model=\"Exp\", range=300, nugget=0))\nvm\n# Krigagem (exemplo):\n# meuse.grid &lt;- ... (defina grade)\n# kr &lt;- krige(log(zinc) ~ sqrt(dist), meuse, meuse.grid, model = vm)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao Minicurso de Estatística Espacial</span>"
    ]
  },
  {
    "objectID": "index.html#apêndice-b-scripts-e-dados",
    "href": "index.html#apêndice-b-scripts-e-dados",
    "title": "Minicurso de Estatística Espacial",
    "section": "0.4 Apêndice B — Scripts e Dados",
    "text": "0.4 Apêndice B — Scripts e Dados\n\nscript_com_covariaveis.R: scripts com exemplos prontos de spatstat e kppm.\nScript_geo_estatistica.R: scripts de variograma e krigagem para meuse.\ndados/: contêm Area_Jernimo_Contorno.kml e outros dados de exemplo.\n\nColoque os scripts no mesmo diretório do projeto e execute bloco-a-bloco no RStudio para reproduzir resultados. Se quiser, eu posso gerar arquivos scripts/ com versões prontas das soluções.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao Minicurso de Estatística Espacial</span>"
    ]
  },
  {
    "objectID": "index.html#referências",
    "href": "index.html#referências",
    "title": "Minicurso de Estatística Espacial",
    "section": "0.5 Referências",
    "text": "0.5 Referências\n\nDiggle, P.J. & Ribeiro, P.J. (2007). Model-based Geostatistics. Springer.\n\nIllian, J., Penttinen, A., Stoyan, H., Stoyan, D. (2008). Statistical Analysis and Modelling of Spatial Point Patterns. Wiley.\n\nAnselin, L. (1988). Spatial Econometrics: Methods and Models. Kluwer.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao Minicurso de Estatística Espacial</span>"
    ]
  },
  {
    "objectID": "dados_areas.html",
    "href": "dados_areas.html",
    "title": "2  Dados de Áreas",
    "section": "",
    "text": "Dados de áreas (areal data) são observações agregadas em unidades espaciais discretas, como bairros, municípios ou regiões administrativas. Essas unidades são representadas por polígonos em um sistema de informação geográfica (SIG). Exemplos comuns incluem taxas de criminalidade por bairro, incidência de doenças por município e dados socioeconômicos por região.\nNesta abordagem, modelamos uma variável resposta agregada em polígonos (ex: taxas de crime por bairro) usando variáveis independentes, corrigindo a autocorrelação espacial via matriz de pesos \\(W\\).\n\nPacotes: spdep, spatialreg.\nReferência: Anselin (1988).\n\n\n2.0.1 Cálculos e Intuições\n\nMatriz de pesos \\(W\\): constrói-se a partir da vizinhança (por exemplo Rainha/Queen). Cada elemento \\(w_{ij}\\) indica influência do polígono \\(j\\) sobre \\(i\\). Em estilo row-standardized (“W”), cada linha é dividida pela soma da linha, de modo que \\(\\sum_j w_{ij}=1\\).\nMoran’s I (teste de autocorrelação espacial): \\[I = \\frac{n}{S_0} \\frac{\\sum_{i}\\sum_{j} w_{ij}(y_i-\\bar{y})(y_j-\\bar{y})}{\\sum_i (y_i-\\bar{y})^2},\\] onde \\(S_0=\\sum_i\\sum_j w_{ij}\\) e \\(n\\) é o número de polígonos. No R usamos lm.morantest() que calcula \\(I\\) nos resíduos do OLS.\nModelos espaciais (intuição matemática):\n\nSpatial Lag (SAR): \\[Y = \\rho W Y + X\\beta + \\varepsilon, \\quad \\varepsilon\\sim N(0,\\sigma^2 I).\\] A estimação procura \\(\\rho,\\beta,\\sigma^2\\) maximizando a verossimilhança (ou por métodos de momentos). No R usamos lagsarlm() que internamente otimiza a verossimilhança do sistema \\((I-\\rho W)Y = X\\beta + \\varepsilon\\).\nSpatial Error (SEM): \\[Y = X\\beta + u, \\quad u = \\lambda W u + \\xi, \\quad \\xi\\sim N(0,\\sigma^2 I).\\] Aqui a dependência aparece no termo de erro e é estimada via errorsarlm().\n\nPassos práticos para análises:\n\nAjustar OLS e calcular resíduos: res = residuals(modelo_ols).\nCalcular Moran’s I nos resíduos: lm.morantest(modelo_ols, listw); se significativo, considerar modelos espaciais.\nAjustar SAR/SEM e comparar AIC/logLik para selecionar modelo.\nInterpretar beta condicionais ao efeito espacial estimado (rho ou lambda).\n\n\nlibrary(spdep)\nlibrary(spatialreg)\n\n# Carregando dados clássicos de Crime em Columbus (Anselin, 1988)\ndata(columbus)\n\n# 1. Definir a Vizinhança e Matriz de Pesos (W)\n# Cria lista de vizinhos (critério Rainha/Queen)\nstr(columbus)\nnb &lt;- poly2nb(columbus)\n# Padroniza a matriz pelas linhas (W)\nlistw &lt;- nb2listw(nb, style = \"W\")\n\n# 2. Modelo OLS (Regressão Linear Padrão)\n# Crime ~ Renda (INC) + Valor da Casa (HOVAL)\nmodelo_ols &lt;- lm(CRIME ~ INC + HOVAL, data = columbus)\n\n# Teste de Moran nos resíduos (verifica se sobrou dependência espacial)\nlm.morantest(modelo_ols, listw)\n\n# 3. Modelos Espaciais com Covariáveis\n\n# Modelo SAR (Spatial Lag Model) - O crime vizinho influencia o crime local\n# Equação: Y = rho*W*Y + X*beta + erro\nmodelo_sar &lt;- lagsarlm(CRIME ~ INC + HOVAL, data = columbus, listw = listw)\n\n# Modelo SEM (Spatial Error Model) - O erro vizinho influencia o erro local\n# Equação: Y = X*beta + u, onde u = lambda*W*u + erro\nmodelo_sem &lt;- errorsarlm(CRIME ~ INC + HOVAL, data = columbus, listw = listw)\n\n# Comparação dos Resultados\nsummary(modelo_sar)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Dados de Áreas</span>"
    ]
  },
  {
    "objectID": "processos_pontuais.html",
    "href": "processos_pontuais.html",
    "title": "3  Processos Pontuais",
    "section": "",
    "text": "Aqui modelamos a intensidade (densidade de pontos) em função de covariáveis ambientais.\nPacote: spatstat. Referências: Illian et al. (2008) e Diggle (2013).\n\n3.0.1 Cálculos passo a passo (Processos Pontuais)\n\nModelo Poisson Inhomogêneo (log-linear): \\[\\log \\lambda(s) = \\beta_0 + \\sum_{k}\\beta_k x_k(s).\\] O ajuste por máxima verossimilhança discretiza a janela ou usa aproximações de Poisson pontual; ppm() resolve o problema maximizando a verossimilhança baseada na função de intensidade.\nLGCP (Cox Log-Gaussiano): \\[\\lambda(s) = \\exp\\{X(s)\\beta + S(s)\\},\\] onde \\(S(s)\\) é um Campo Gaussiano com variograma especificado. A inferência estima \\(\\beta\\) e os parâmetros do campo (variância e escala) via métodos aproximados (ex.: Laplace, Palm likelihood, ou métodos de mínimos quadrados dependendo do method). Em R usamos kppm(..., clusters = \"LGCP\").\nPassos práticos em R:\n\nVisualizar pontos e covariáveis: plot(bei.extra) + plot(bei, add=TRUE).\nAjustar ppm() para efeitos fixos; verificar resíduos (P-P plot) para falta de ajuste.\nAjustar kppm(..., clusters = \"LGCP\"); inspecionar Trend coefficients (betas) e Cluster parameters (sigma2, escala).\n\n\nlibrary(spatstat)\n\n# Carregando dados de árvores (bei) e covariáveis (bei.extra: elevação e gradiente)\ndata(bei) \n\n# Visualizando\nplot(bei.extra$grad, main = \"Covariável: Gradiente do Terreno\")\nplot(bei, add = TRUE, pch = \".\", cols = \"white\")\n\n# Abordagem 1: Poisson Inhomogêneo (Illian et al., 2008)\n# A intensidade lambda depende deterministícamente do Gradiente\n# log(lambda) = beta0 + beta1 * gradiente\nmodelo_poisson &lt;- ppm(bei ~ grad, data = bei.extra)\n\n# Abordagem 2: LGCP com Covariável (Diggle, 2013)\n# A intensidade depende do Gradiente + um Cluster Estocástico (Campo Gaussiano)\n# Isso captura a agregação que a covariável não explicou.\nmodelo_cox &lt;- kppm(bei ~ grad, data = bei.extra, clusters = \"LGCP\")\n\n# Comparação\nprint(modelo_poisson) # Coeficientes da covariável\nprint(modelo_cox)     # Coeficientes + Parâmetros do cluster espacial",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Processos Pontuais</span>"
    ]
  },
  {
    "objectID": "geoestatistica.html",
    "href": "geoestatistica.html",
    "title": "4  Geoestatística",
    "section": "",
    "text": "4.1 Geoestatística\n3.1. Geoestatística com Covariáveis (Krigagem Universal) Aqui modelamos uma superfície contínua onde a tendência (média) não é constante, mas depende de uma covariável.\nPacote: gstat.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geoestatística</span>"
    ]
  },
  {
    "objectID": "geoestatistica.html#geoestatística",
    "href": "geoestatistica.html#geoestatística",
    "title": "4  Geoestatística",
    "section": "",
    "text": "#| message: false\n#| warning: false\nlibrary(gstat)\nlibrary(sp)\n\n# Dados de metais pesados no rio Meuse\ndata(meuse)\n# Definindo que é um objeto espacial\ncoordinates(meuse) = ~x+y\n\n# O variograma é calculado sobre os RESÍDUOS da regressão: log(zinco) ~ sqrt(distancia)\n# Isso remove a tendência explicada pela proximidade do rio.\nv_covariavel &lt;- variogram(log(zinc) ~ sqrt(dist), meuse)\n\n# Ajuste do modelo teórico ao variograma residual\nmodelo_v &lt;- fit.variogram(v_covariavel, vgm(1, \"Exp\", 300, 1))\n\nplot(v_covariavel, modelo_v, main = \"Variograma Residual (Krigagem Universal) \")\n\n# Para realizar a predição (Krigagem), usaríamos a função krige:\n#k_univ &lt;- krige(log(zinc) ~ sqrt(dist), meuse, meuse.grid, model = modelo_v)\n\n### Cálculos detalhados (Geoestatística)\n\n- **Variograma empírico:** para lag $h$ estima-se\n  $$\\hat{\\gamma}(h) = \\frac{1}{2N(h)}\\sum_{i,j:\\|s_i-s_j\\|\\approx h} (Z(s_i)-Z(s_j))^2,$$ \nonde $N(h)$ é o número de pares na banda de distância $h$. Em R `variogram()` calcula isto sobre os resíduos da tendência.\n\n- **Ajuste do modelo teórico:** escolhe-se uma forma (Exponencial, Spherical, Matérn) e ajusta-se parâmetros: nugget, sill (partial sill) e range. Em `fit.variogram()` a função minimiza a soma de quadrados ponderada entre o empírico e o teórico.\n\n- **Krigagem (preditor linear ótimo):** para um ponto $s_0$ com média conhecida $m(s)$, \n  $$\\hat{Z}(s_0) = m(s_0) + c_0^T C^{-1} (Z - m),$$ \nonde $C$ é a matriz de covariâncias entre observações, $c_0$ é vetor de covariâncias entre $s_0$ e observações, e $m$ é a tendência avaliada nas locações. `krige()` resolve esse sistema linear usando o modelo de variograma ajustado.\n\n- Passos práticos:\n  1. Ajustar uma regressão para extrair tendência; calcular resíduos.\n  2. Calcular variograma empírico sobre resíduos: `variogram(res ~ 1, data)`.\n  3. Ajustar modelo teórico: `fit.variogram()`.\n  4. Prever com `krige()` usando a fórmula e o modelo de variograma.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Geoestatística</span>"
    ]
  }
]